# File: app/schemas/prediction.py

from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
from datetime import datetime

class PredictionBase(BaseModel):
    """
    Base schema for common prediction attributes.
    """
    symbol: str = Field(..., example="AAPL")
    # 'predicted_price' was used in the Prediction SQLAlchemy model and MLEngine response
    predicted_price: float = Field(..., example=155.75, description="The predicted price for the symbol.")
    confidence: Optional[float] = Field(None, example=0.78, description="Model confidence for the prediction (e.g., 0-1).")
    model_name: str = Field(..., example="lstm_AAPL_v1", description="Name or type of the ML model used.")
    # 'features' was a JSON field in the model, can be a Dict here
    features: Optional[Dict[str, Any]] = Field(None, description="Features used for making this prediction.", example={"rsi": 65, "macd_signal": 0.5})
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Timestamp when the prediction was generated or recorded.")


class PredictionCreate(PredictionBase):
    """
    Schema for creating a new prediction record.
    Predictions are typically generated by the ML engine and logged by the system.
    This schema could be used if there's an internal API or process to log predictions.
    It expects user_id to be set by the system if predictions are user-specific.
    """
    # If predictions are always tied to a user when logged to DB:
    # user_id: int # This would be set by the endpoint logic, not part of the direct request body usually.
    pass


class PredictionResponse(PredictionBase):
    """
    Schema for returning prediction information to the client.
    Includes the prediction ID and user ID if applicable.
    """
    id: int
    user_id: Optional[int] = Field(None, description="ID of the user this prediction is associated with, if any.")
    # Inherits all fields from PredictionBase

    # Pydantic V2 configuration
    model_config = {
        "from_attributes": True
    }

# This schema can also be used for the /predict/{symbol} endpoint in endpoints.py
# if it's more specific than returning the direct dict from MLEngine.
# The MLEngine predict method returns:
# {
#     "symbol": symbol,
#     "predicted_price": round(float(predicted_actual_price), 2),
#     "confidence": round(float(confidence_metric), 2),
#     "model_type": model_type, # Matches model_name
#     "latest_data_date": str(latest_date_in_data)
# }
# So, we can create a specific response for that endpoint if needed, or adapt PredictionResponse.
# Let's refine PredictionResponse to better match what MLEngine provides for the /predict endpoint for now.

class GetPredictionResponse(BaseModel):
    """
    Schema for the response from the /predict/{symbol} endpoint.
    Matches the output structure of MLEngine.predict.
    """
    symbol: str
    predicted_price: float
    confidence: float
    model_type: str # This was model_name in PredictionBase, but MLEngine uses model_type
    latest_data_date: str # Date of the last data point used for prediction

    # No 'id' or 'user_id' here as it's a direct model prediction, not necessarily a stored DB record.
    # No from_attributes needed as it's built from a dict.